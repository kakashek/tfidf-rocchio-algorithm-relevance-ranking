{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d41407-8856-44db-b2f5-a139bb0009a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob, os\n",
    "import string\n",
    "import sys\n",
    "import math\n",
    "from stemming.porter2 import stem\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef031bb2-5dd8-4f45-ba4e-9e3e7d74bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get synonyms\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d3ef50-809d-41ef-96e6-e1d84713296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function parse_docs to parse data collection\n",
    "def parse_docs(folder_number, path, stop_ws):\n",
    "    folder_number = str(folder_number)\n",
    "    doc_list = []\n",
    "    folder_name = \"Dataset\"+folder_number\n",
    "    inputpath = os.path.join(path, folder_name)\n",
    "    files = os.listdir(inputpath) \n",
    "    os.chdir(inputpath)\n",
    "    for doc in files:\n",
    "        if doc.endswith(\".xml\"):\n",
    "            myfile = open(doc)\n",
    "            start_end = False\n",
    "            file_ = myfile.readlines()\n",
    "            word_count = 0 \n",
    "            document = {}\n",
    "            term_list = {}\n",
    "            doc_id = 0\n",
    "            for line in file_: \n",
    "                line = line.strip()\n",
    "                if(start_end == False):\n",
    "                    if line.startswith(\"<newsitem \"):\n",
    "                        for part in line.split():\n",
    "                            if part.startswith(\"itemid=\"):\n",
    "                                doc_id = part.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                                break  \n",
    "                    if line.startswith(\"<title>\"):\n",
    "                        query_list = {}\n",
    "                        line = line.strip()\n",
    "                        line = line.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))             \n",
    "                    if line.startswith(\"<text>\"):\n",
    "                        start_end = True  \n",
    "                elif line.startswith(\"</text>\"):\n",
    "                    break\n",
    "                else:\n",
    "                    line = line.replace(\"<p>\", \"\").replace(\"</p>\", \"\")\n",
    "                    line = line.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "                    line = line.replace(\"\\\\s+\", \" \")\n",
    "                    for term in line.split():\n",
    "                        word_count += 1 \n",
    "                        term = stem(term.lower())\n",
    "                        if len(term) > 2 and term not in stop_words: \n",
    "                            try:\n",
    "                                term_list[term] += 1\n",
    "                            except KeyError:\n",
    "                                term_list[term] = 1\n",
    "            doc_list.append({doc_id: term_list})\n",
    "            myfile.close()\n",
    "    return doc_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbe3d94-4553-4609-aca1-df1959f5f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to parse query from Queries.txt\n",
    "def parse_query(inputpath, stop_words):\n",
    "    query_list = {}\n",
    "    with open(os.path.join(inputpath, 'Queries.txt'), 'r') as f:       \n",
    "        query_lines = f.readlines()\n",
    "        query = {}\n",
    "        query_num = 0\n",
    "        for i in range(len(query_lines)):\n",
    "            if query_lines[i].startswith('<num>'):\n",
    "                query_num = query_lines[i].split(':')[1].strip(' R').strip('\\n').strip(' ')\n",
    "            if query_lines[i].startswith('<title>'):\n",
    "                query_lines[i] = query_lines[i].replace('<title>', '')\n",
    "                for term in query_lines[i].split():\n",
    "                    term = term.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "                    if len(term) > 2 and term not in stop_words:\n",
    "                        try:\n",
    "                            query[stem(term)] += 1.5\n",
    "                        except KeyError:\n",
    "                            query[stem(term)] = 1.5\n",
    "                        # Find synonyms for title query\n",
    "                        synonyms = get_synonyms(term)\n",
    "                        for synonym in synonyms:\n",
    "                            if stem(synonym) not in query and '_' not in stem(synonym) and synonym not in stop_words:\n",
    "                                query[stem(synonym)] = 0.5\n",
    "            if query_lines[i].startswith('<desc>'):\n",
    "                j = 1\n",
    "                while query_lines[i+j].startswith('<narr>') != True:\n",
    "                    for term in query_lines[i+j].split():\n",
    "                        term = term.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "                        if len(term) > 2 and term not in stop_words:\n",
    "                            try:\n",
    "                                query[stem(term)] += 0.75\n",
    "                            except KeyError:\n",
    "                                query[stem(term)] = 0.75\n",
    "                    j += 1\n",
    "            if query_lines[i].startswith('</Query>'):\n",
    "                query_list.update({query_num: query})\n",
    "                query = {}\n",
    "                query_num = 0\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abdd77b-a3dd-4602-b72b-b78ec86cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model functions\n",
    "def rocchhio_tfidf_model(folder_number, coll, query_list):\n",
    "    \n",
    "    # Calculate document frequency\n",
    "    document_frequency = {}\n",
    "    folder_number = str(folder_number)\n",
    "    for doc in coll:\n",
    "        for terms in doc.values():\n",
    "            for term in terms:\n",
    "                if term not in document_frequency:\n",
    "                    document_frequency[term] = 1\n",
    "                else:\n",
    "                    document_frequency[term] += 1\n",
    "\n",
    "                    \n",
    "    # Calculate td*idf score for each term for each document\n",
    "    document_list = {}\n",
    "    for doc in coll:\n",
    "        tfidf_list = {}\n",
    "        tfidf_total = 0\n",
    "        for terms in doc.values():\n",
    "            for term, value in terms.items():\n",
    "                tf = math.log(value, 10) + 1\n",
    "                idf = math.log(len(coll) / document_frequency[term], 10)\n",
    "                tfidf_value = tf * idf\n",
    "                tfidf_list[term] = tfidf_value\n",
    "                tfidf_total += tfidf_value ** 2\n",
    "        for term in tfidf_list:\n",
    "            tfidf_list[term] /= math.sqrt(tfidf_total)\n",
    "        document_list[list(doc.keys())[0]] = tfidf_list\n",
    "\n",
    "        \n",
    "    # Retrieve query terms \n",
    "    try:\n",
    "        query_terms = query_list[folder_number]\n",
    "    except KeyError:\n",
    "        print(\"Incorrect folder number\")\n",
    "  \n",
    "    \n",
    "    # Calculate initial document score for each document in the folder\n",
    "    document_score = {}\n",
    "    for doc_id, tfidf_list in document_list.items():\n",
    "        score = 0\n",
    "        for term in query_terms:\n",
    "            if term in tfidf_list:\n",
    "                term_score = tfidf_list[term] * query_terms[term]\n",
    "                score += term_score\n",
    "        document_score[doc_id] = score\n",
    "    document_score_sorted = dict(sorted(document_score.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    \n",
    "    # Append the top 10 highest ranking into a list of relevant and non-relevant documents with pseudo-relevance feedback\n",
    "    relevant_docs = {}\n",
    "    non_relevant_docs = {}\n",
    "    i = 0\n",
    "    for doc in document_score_sorted:\n",
    "        if i < 10:\n",
    "            relevant_docs[doc] = document_score_sorted[doc]\n",
    "            i += 1\n",
    "        else:\n",
    "            non_relevant_docs[doc] = document_score_sorted[doc]\n",
    "\n",
    "            \n",
    "    # Calculate new document score using Rocchio's algorithm\n",
    "    alpha = 1\n",
    "    beta = 2\n",
    "    gamma = 0.5\n",
    "    updated_document_score = {}\n",
    "    for doc_id, tfidf_list in document_list.items():\n",
    "        score = alpha * document_score[doc_id]\n",
    "        if doc_id in relevant_docs:\n",
    "            score += beta * sum(tfidf_list.get(term, 0) for term in query_terms.keys())\n",
    "        elif doc_id in non_relevant_docs:\n",
    "            score -= gamma * sum(tfidf_list.get(term, 0) for term in query_terms.keys())\n",
    "        updated_document_score[doc_id] = score\n",
    "    updated_document_score_sorted = dict(sorted(updated_document_score.items(), key=lambda x: x[1], reverse=True))\n",
    "    return updated_document_score_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738f3c77-b625-4ed0-be65-19da65e9d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate the benchmark results for the model\n",
    "def test_results(folder_number, updated_document_score_sorted, feedback_path):\n",
    "    os.chdir(feedback_path)\n",
    "    file_name = 'Dataset'+str(folder_number)+'.txt'\n",
    "    benFile = open(file_name)\n",
    "    file_ = benFile.readlines()\n",
    "    ben={}\n",
    "    for line in file_:\n",
    "        line = line.strip()\n",
    "        lineList = line.split()\n",
    "        ben[lineList[1]]=float(lineList[2])\n",
    "    benFile.close()\n",
    "    \n",
    "    # Calculate average precision\n",
    "    ri = 0\n",
    "    map1 = 0.0\n",
    "    R = len([id for (id, v) in ben.items() if v > 0])\n",
    "    i = 0\n",
    "    for (key, value) in updated_document_score_sorted.items():\n",
    "        i += 1\n",
    "        if ben[key] > 0:\n",
    "            ri += 1\n",
    "            pi = float(ri) / float(i)\n",
    "            recall = float(ri) / float(R)\n",
    "            map1 += pi\n",
    "    map1 /= float(ri)\n",
    "    \n",
    "    # Calculate precision@12\n",
    "    ri = 0\n",
    "    map2 = 0.0\n",
    "    R = len([id for (id, v) in ben.items() if v > 0])\n",
    "    i = 0\n",
    "    for (key, value) in updated_document_score_sorted.items():\n",
    "        i += 1\n",
    "        if ben[key] > 0:\n",
    "            ri += 1\n",
    "            pi = float(ri) / float(i)\n",
    "            recall = float(ri) / float(R)\n",
    "            map2 += pi\n",
    "        if i == 12:\n",
    "            break\n",
    "    map2 /= float(ri)\n",
    "    \n",
    "    # Calculate DCG12\n",
    "    ri = 0\n",
    "    dcg = 0.0\n",
    "    R = len([id for (id, v) in ben.items() if v > 0])\n",
    "    i = 0\n",
    "    for (key, value) in updated_document_score_sorted.items():\n",
    "        i += 1\n",
    "        if ben[key] > 0:\n",
    "            if i == 1:\n",
    "                dcg = 1\n",
    "            else:     \n",
    "                dcg += ben[key]/math.log2(int(i))\n",
    "        if i == 12:\n",
    "            break\n",
    "    return map1, map2, dcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb848f39-f03b-4c4a-a5c7-ced3f36a08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6491781165694209, 0.8234599277165888, 0.3089927043663835, 0.8603091069257, 0.7570945139419404, 0.6052188552188551, 0.17222222222222225, 0.13874269005847953, 0.7061264294296585, 0.44698412698412693, 0.6388888888888888, 0.8477564102564102, 0.6722581025212603, 0.885, 0.3888888888888889, 0.29821784805931273, 0.31746031746031744, 0.2333333333333333, 0.2070378151260504, 0.5042274942633366, 0.5776229167388518, 0.6106988077805144, 0.3636363636363636, 0.5642446633825944, 0.5588041847508888, 0.7192441107477707, 0.33772727272727276, 0.10499222999222999, 0.5090728634753934, 0.34722222222222215, 0.14454334365325078, 0.2000758709227402, 0.5425, 0.2753614577143989, 0.7485738019290652, 0.2502830474441728, 0.3833333333333333, 0.5371845619339354, 0.6464646464646464, 0.7554097417733783, 0.5871436372948898, 0.38038277511961727, 0.13285547785547785, 0.44490740740740736, 0.2430933655979028, 0.3285779221214117, 0.3715709728867624, 0.3396809199192596, 0.19696192696192696, 0.1655877467265976]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------- Main --------------------------------- #\n",
    "\n",
    "# Read stop words file\n",
    "stopwords_f = open(os.path.join(sys.path[0], \"common-english-words.txt\"), \"r\")\n",
    "stop_words = stopwords_f.read().split(',')\n",
    "stopwords_f.close()\n",
    "\n",
    "# Write input path\n",
    "data_path = os.path.join(sys.path[0], \"DataSets\")\n",
    "feedback_path = os.path.join(sys.path[0], \"Feedback\")\n",
    "output_path = os.path.join(sys.path[0], \"Output\")\n",
    "path = os.path.join(sys.path[0])\n",
    "\n",
    "# Parse query\n",
    "query_list = parse_query(path, stop_words)\n",
    "\n",
    "# Define output files\n",
    "output_file_names = [\"Rocchio_rankings.dat\", \"Rocchio_results.dat\"]\n",
    "os.chdir(output_path)\n",
    "for file in output_file_names:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except Exception:\n",
    "        pass \n",
    "\n",
    "\n",
    "# Run the model through each document and query and output results\n",
    "document_score = {}\n",
    "average_precision_list = {}\n",
    "precision12_list = {}\n",
    "dcg_list = {}\n",
    "average_precision_array = []\n",
    "precision12_array = []\n",
    "dcg_array = []\n",
    "\n",
    "for i in range (101, 151):\n",
    "    document_list = parse_docs(i, data_path, stop_words)\n",
    "    updated_document_score_sorted = rocchhio_tfidf_model(i, document_list, query_list)\n",
    "\n",
    "    # Remove old document rankings\n",
    "    file_name = \"Rocchio_R\"+str(i)+\"Rankings.dat\"\n",
    "    try:\n",
    "        os.remove(file_name)\n",
    "    except Exception:\n",
    "        pass \n",
    "\n",
    "    # Output document rankings\n",
    "    with open(os.path.join(output_path, file_name), \"w\") as f:\n",
    "        f.write(f\"Query{i} (DocID Weight):\\n\")\n",
    "        count = 0\n",
    "        for key, value in updated_document_score_sorted.items():\n",
    "            count += 1\n",
    "            f.write(f\"{key} {value}\\n\")\n",
    "            if count == 12:\n",
    "                break\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Save test results\n",
    "    average_precision, precision12, dcg = test_results(i, updated_document_score_sorted, feedback_path)\n",
    "    average_precision_list.update({i: average_precision})\n",
    "    precision12_list.update({i: precision12})\n",
    "    dcg_list.update({i: dcg})\n",
    "\n",
    "# Remove test results\n",
    "try:\n",
    "    os.remove(\"Rocchio_results.txt\")\n",
    "except Exception:\n",
    "    pass   \n",
    "\n",
    "# Output test results                \n",
    "with open(os.path.join(output_path, \"Rocchio_results.dat\"), \"w\") as f:\n",
    "    f.write(f\"Average Precision:\\n\")\n",
    "    sum_average_precision = 0\n",
    "    for key, value in average_precision_list.items():\n",
    "        f.write(f\"R{key}: {value}\\n\")\n",
    "        average_precision_array.append(value)\n",
    "        sum_average_precision += value\n",
    "    f.write(f\"MAP: {sum_average_precision/len(average_precision_list)}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    f.write(f\"Precision@12:\\n\")\n",
    "    sum_precision_12 = 0\n",
    "    for key, value in precision12_list.items():\n",
    "        f.write(f\"R{key}: {value}\\n\")\n",
    "        precision12_array.append(value)\n",
    "        sum_precision_12 += value\n",
    "    f.write(f\"Average: {sum_precision_12/len(precision12_list)}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    f.write(f\"DCG12:\\n\")\n",
    "    sum_dcg = 0\n",
    "    for key, value in dcg_list.items():\n",
    "        f.write(f\"R{key}: {value}\\n\")\n",
    "        dcg_array.append(value)\n",
    "        sum_dcg += value\n",
    "    f.write(f\"Average: {sum_dcg/len(dcg_list)}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    print(average_precision_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a44fcd9-8f20-442a-a18a-68df932ad03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision: [0.6491781165694209, 0.8234599277165888, 0.3089927043663835, 0.8603091069257, 0.7570945139419404, 0.6052188552188551, 0.17222222222222225, 0.13874269005847953, 0.7061264294296585, 0.44698412698412693, 0.6388888888888888, 0.8477564102564102, 0.6722581025212603, 0.885, 0.3888888888888889, 0.29821784805931273, 0.31746031746031744, 0.2333333333333333, 0.2070378151260504, 0.5042274942633366, 0.5776229167388518, 0.6106988077805144, 0.3636363636363636, 0.5642446633825944, 0.5588041847508888, 0.7192441107477707, 0.33772727272727276, 0.10499222999222999, 0.5090728634753934, 0.34722222222222215, 0.14454334365325078, 0.2000758709227402, 0.5425, 0.2753614577143989, 0.7485738019290652, 0.2502830474441728, 0.3833333333333333, 0.5371845619339354, 0.6464646464646464, 0.7554097417733783, 0.5871436372948898, 0.38038277511961727, 0.13285547785547785, 0.44490740740740736, 0.2430933655979028, 0.3285779221214117, 0.3715709728867624, 0.3396809199192596, 0.19696192696192696, 0.1655877467265976]\n",
      "precision12: [0.7066498316498316, 0.9622222222222223, 0.4333333333333333, 0.7980122655122656, 0.865909090909091, 0.7575757575757575, 0.225, 0.125, 0.928409090909091, 0.4694444444444444, 0.6388888888888888, 0.925, 0.8441043083900226, 0.885, 0.5, 0.40277777777777773, 0.31746031746031744, 0.2333333333333333, 0.25, 0.611904761904762, 0.7591836734693878, 0.6163265306122448, 0.5, 0.75, 0.6925170068027212, 0.8596165739022883, 0.33772727272727276, 0.1111111111111111, 0.788888888888889, 0.34722222222222215, 0.08333333333333333, 0.29166666666666663, 0.6, 0.41666666666666663, 0.912878787878788, 0.2111111111111111, 0.3833333333333333, 1.0, 0.6464646464646464, 0.8398027898027899, 0.6572356215213357, 0.5909090909090909, 0.12878787878787878, 0.45888888888888885, 1.0, 0.18333333333333335, 0.38272727272727275, 0.1, 0.14090909090909093, 0.19642857142857142]\n",
      "dcg: [3.405559698767598, 5.200104124088254, 2.0964723109590646, 4.543559338088346, 4.423342259573597, 2.2890648263178877, 0.7640098914067264, 0.3333333333333333, 4.538553940861261, 1.8770711884305795, 2.1309297535714578, 3.4642630869047912, 4.022787958033084, 3.394939644978184, 1.5, 1.7201861405678749, 1.3026018174652085, 1.0799729413151111, 0.5, 2.8668566864965266, 3.78601283140042, 3.28601283140042, 1.5, 2.720186140567875, 3.290231424865667, 4.091666643783097, 1.7188704706102858, 0.31546487678572877, 3.247424626021168, 1.3511158941393324, 0.27894294565112987, 0.9642630869047908, 2.2474246260211674, 1.3868528072345416, 4.51646689084841, 0.7461414348591218, 1.709619503724523, 2.6309297535714578, 1.9199945798893454, 4.671639585098207, 3.4785194510176387, 1.2890648263178879, 0.5680077719690177, 2.156014134081709, 1, 0.709619503724523, 2.2558905748675406, 0.3010299956639812, 0.5900948219818691, 0.6895405204413555]\n"
     ]
    }
   ],
   "source": [
    "print(\"average_precision:\", average_precision_array)\n",
    "print(\"precision12:\",precision12_array)\n",
    "print(\"dcg:\", dcg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56909f5b-6d6e-48de-87da-452341cf24f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
